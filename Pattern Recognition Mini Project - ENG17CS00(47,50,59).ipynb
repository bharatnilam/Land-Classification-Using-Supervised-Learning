{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Land Classification Using Supervised Learning\n",
    "### Pattern Recognition Mini Project (VII Semester CSE, A Section)\n",
    "Submitted by:\n",
    "B P Gayathri Ananya - ENG17CS0047  \n",
    "Bharat Nilam - ENG17CS0050  \n",
    "Chirag P D - ENG17CS0059  \n",
    "\n",
    "### Introduction\n",
    "A land use classification is a classification providing information on land cover, and the types\n",
    "of human activity involved in land use. It may also facilitate the assessment of environmental\n",
    "impacts on, and potential or alternative uses of, land. Classifying and mapping land cover is an\n",
    "integral step in understanding the Earth's biophysical systems. Data on the area and distribution\n",
    "of wildlife habitat, for example, are useful in managing and mitigating development impacts\n",
    "on protected and endangered species."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Installing package dependencies if running on Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define functions\n",
    "Define functions to read image from Amazon S3 and stream to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream2npy(img_stream):\n",
    "    arr = np.asarray(bytearray(img_stream['Body'].read()), dtype=np.uint8)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get data from cloud\n",
    "We will get data from an S3 bucket in the form of a geotif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = 'uw-geohack'\n",
    "KEY_DG = 'la_digitalglobe_small.tif' \n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "s3_client = boto3.client('s3',config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "img_stream_dg = s3_client.get_object(Bucket=BUCKET_NAME, Key=KEY_DG)\n",
    "\n",
    "print('DG:', img_stream_dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data into memory and convert it to a numpy array in RGB space\n",
    "\n",
    "img1=stream2npy(img_stream_dg)\n",
    "img1_de = cv2.imdecode(img1, -1)\n",
    "img1_rgb = cv2.cvtColor(img1_de, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(18, 16))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img1_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DG = 'training_data_dg.tif'\n",
    "\n",
    "train_stream2 = s3_client.get_object(Bucket=BUCKET_NAME, Key=TRAIN_DG)\n",
    "train2=stream2npy(train_stream2)\n",
    "train2_de = cv2.imdecode(train2, -1)\n",
    "\n",
    "print('Shape of the Training data:', train2_de.shape)\n",
    "print('Shape of the Image data:', img1_rgb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. How the training data was made..\n",
    "The training data was created in QGIS as a geojson vector layer. This layer was rasterized using the command line rasterio tools.\n",
    "\n",
    "### 7. Evaluate training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {'pool': 1, 'street': 2, 'grass': 3, 'roof': 4, 'tree': 5, 'shadow': 6}\n",
    "n_classes = len(classes)\n",
    "print('Unique values in training array: ',np.unique(train2_de))\n",
    "\n",
    "# create a colour palette we will use to colour the predictions\n",
    "palette = np.uint8([[0, 0, 0],[0, 255, 255], [128, 128, 128], [0, 255, 0],[255, 255, 255],[0, 102, 0],[51, 51, 51]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statsdata(arr):\n",
    "    '''generate histogram of training data'''\n",
    "    fig=plt.figure(figsize=(7, 7))\n",
    "    bins = range(8)\n",
    "    plt.hist(arr, bins=bins) \n",
    "    bins_labels(bins, fontsize=20)\n",
    "    plt.title('Distribution of Training Data Classes')\n",
    "    plt.xlabel('Classes')\n",
    "\n",
    "def bins_labels(bins, **kwargs):\n",
    "    '''center the histogram bin labels due to OCD'''\n",
    "    bin_w = (max(bins) - min(bins)) / (len(bins) - 1)\n",
    "    plt.xticks(np.arange(min(bins)+bin_w/2, max(bins), bin_w), bins, **kwargs)\n",
    "    plt.xlim(bins[0], bins[-1])\n",
    "\n",
    "statsdata(train2_de[train2_de>0].ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Create training data mask\n",
    "Mask out the parts of the RGB image we wont be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols, bands = img1_rgb.shape\n",
    "full=img1_rgb[:,:,0:3]   \n",
    "full=full.ravel()\n",
    "full=full.reshape((-1, 1))  \n",
    "\n",
    "red=img1_rgb[:,:,0]\n",
    "green=img1_rgb[:,:,1] \n",
    "blue=img1_rgb[:,:,2]\n",
    "\n",
    "# remove all the 'class 0' from the training data\n",
    "red=np.where(train2_de>0, red,0)\n",
    "green=np.where(train2_de>0, green,0)\n",
    "blue=np.where(train2_de>0, blue,0)\n",
    "\n",
    "# create a mask with the same dimensions\n",
    "Xtrain=np.dstack((red,green,blue))\n",
    "Ylabel=np.dstack((train2_de,train2_de,train2_de))\n",
    "\n",
    "# flatten\n",
    "data = Xtrain.ravel()     \n",
    "label= Ylabel.ravel()  \n",
    "\n",
    "# remove all the 'class 0' from the training data\n",
    "l=label[label>0]\n",
    "d=data[label>0]\n",
    "d=d.reshape((-1, 1)) \n",
    "\n",
    "\n",
    "plt.imshow(Xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Training the SVM\n",
    "What is a Support Vector Machine (SVM)? Given a set of labeled training data (supervised learning), the SVM outputs an optimal hyperplane which categorizes new data (not used in training). For a simple case of two classes in 2 dimensional space, the hyperplane is a line dividing a plane in two parts where each of the 2 classes lay on either side. SVMs are useful for classification problems where you would like to different among mulitple classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(d, l, test_size=0.25)\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_t = clf.predict(full)\n",
    "predicted=y_t.reshape(rows, cols,3)\n",
    "\n",
    "fig=plt.figure(figsize=(18, 16))\n",
    "plt.imshow(palette[predicted][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Model Performance\n",
    "Create confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "expected = y_test\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (clf, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "print ('Accuracy Score :',accuracy_score(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Train Random Forest Classifier\n",
    "What is a random forest (RF) classifier? An RF classifier constructs decision trees during supervised training and outputs the class that is the mode of the classification of the individual trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_rf = clf.predict(full)\n",
    "predictedRF=y_rf.reshape(rows, cols,3)\n",
    "\n",
    "fig=plt.figure(figsize=(18, 16))\n",
    "plt.imshow(palette[predictedRF][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Model Performance - RF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "expected = y_test\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (clf, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "print ('Accuracy Score :',accuracy_score(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Metrics Used\n",
    "recall = true positive / (true positive + false positive)\n",
    "\n",
    "precision = true positive / (true positive + false negative)\n",
    "\n",
    "accuracy = true positive + true negative /(true positive + false negative + false positive + true negative)\n",
    "\n",
    "f1 = 2 * (recall * precision)/(recall + precision)\n",
    "\n",
    "support = sum rows of matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
